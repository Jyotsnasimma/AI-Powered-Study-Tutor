{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42eb255-06bb-4c6b-89d3-c4d935521f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad1caa0-797a-45f2-8fc3-5c8e6fb0ade3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (0.3.67)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (0.4.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2->langchain) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from faiss-cpu) (23.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (2.98)\n",
      "Requirement already satisfied: comtypes in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from pyttsx3) (1.4.11)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (4.53.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (5.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.53.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (0.33.1)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install faiss-cpu\n",
    "!pip install pyttsx3\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install sentence-transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b168ce5b-97b5-44a9-9656-edd40ff20a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymupdf in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (1.26.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a130728d-0f33-4bab-ae50-d1000fc3bc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: SpeechRecognition in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (3.14.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from SpeechRecognition) (4.14.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyaudio in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (0.2.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition\n",
    "!pip install pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fe4d84-652f-49d6-947b-597baf28ef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length: 84972\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def load_pdf(path):\n",
    "    doc = fitz.open(\"DSA Full Notes GR-20.pdf\")\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "pdf_path = \"DSA Full Notes GR-20.pdf\"  # Make sure this file is in the same folder as your notebook\n",
    "raw_text = load_pdf(pdf_path)\n",
    "print(\"Text length:\", len(raw_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba74eab1-1d5b-46ac-ad10-e715fada0a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (5.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.53.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (0.33.1)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.2.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\simma_4uy3cu0\\appdata\\roaming\\python\\python311\\site-packages (from faiss-cpu) (23.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n",
    "!pip install faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d957b969-b7bd-4dc4-a5b6-6cae064f8286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 213\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Define your chunking method\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # Each chunk will have ~500 characters\n",
    "    chunk_overlap=100  # Overlap between chunks (helps for continuity)\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(raw_text)\n",
    "print(f\"Total chunks created: {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb6d786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Extracting PDF text...\n",
      "üîÑ Splitting into chunks...\n",
      "‚úÖ PDF split into 26 chunks.\n",
      "üîç Creating FAISS index...\n",
      "‚úÖ Ready! Ask any question (type 'exit' to quit).\n",
      "üîç Searching PDF for relevant content...\n",
      "ü§ñ Generating answer...\n",
      "\n",
      "üí¨ AI Tutor Answer:\n",
      "Time Series Analytics, also known as Trend Analysis, is an important tool for forecasting future outcomes based on historical data. Time Series Analytics involves analyzing and predicting trends in a dataset over a specific period of time, typically over several months or years. This technique allows businesses to make informed decisions about their operations by identifying patterns and trends that can be used to forecast future performance and make strategic decisions. Some common applications for Time Series Analytics include:\n",
      "\n",
      "1. Predicting demand: By analyzing historical sales data, businesses can predict future demand based on past trends and customer behavior. This helps them plan their inventory levels and product offerings accordingly.\n",
      "\n",
      "2. Estimating cash flow: Time series analysis can help businesses forecast future cash flows by analyzing changes in revenue, profitability, and expenses over time.\n",
      "\n",
      "3. Identifying seasonality: By analyzing sales patterns over different seasons or holiday periods, businesses can identify when to launch new products or promote existing ones.\n",
      "\n",
      "4. Making strategic decisions: Time series analysis can help businesses make informed decisions by identifying patterns and trends that are indicative of upcoming market shifts or industry developments.\n",
      "\n",
      "In summary, Time Series Analytics is an important tool for forecasting future outcomes based on historical data. It involves analyzing and predicting trends in a dataset over a specific period of time, typically over several months or years. This technique can help businesses make informed decisions about their operations, identify patterns and trends that can be used to forecast future performance, and predict demand and cash flows.\n",
      "\n",
      "üîä Speaking answer...\n",
      "üëã Exiting AI Tutor. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pyttsx3\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Extract text from PDF\n",
    "# ------------------------------\n",
    "def extract_pdf_text(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Split text into chunks\n",
    "# ------------------------------\n",
    "def split_into_chunks(text, chunk_size=500):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Create FAISS index\n",
    "# ------------------------------\n",
    "def create_faiss_index(chunks, model):\n",
    "    embeddings = model.encode(chunks)\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(np.array(embeddings))\n",
    "    return index, embeddings\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Find top N best chunks\n",
    "# ------------------------------\n",
    "def find_top_chunks(question, chunks, model, index, top_n=3):\n",
    "    q_embedding = model.encode([question])\n",
    "    distances, indices = index.search(np.array(q_embedding), k=top_n)\n",
    "    return [chunks[i] for i in indices[0]]\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Ask TinyLLaMA using Ollama\n",
    "# ------------------------------\n",
    "def ask_local_llm(context, question):\n",
    "    prompt = f\"\"\"You are a helpful AI tutor. Based only on the textbook content below, answer the question clearly and accurately.\n",
    "\n",
    "Text:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    response = ollama.chat(\n",
    "        model='tinyllama',\n",
    "        messages=[{'role': 'user', 'content': prompt}]\n",
    "    )\n",
    "    return response['message']['content']\n",
    "\n",
    "# ------------------------------\n",
    "# 6. Speak the answer (TTS)\n",
    "# ------------------------------\n",
    "def speak_text(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# ------------------------------\n",
    "# MAIN SCRIPT (Interactive Chat with Voice)\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = r\"DSA Full Notes GR-20.pdf\"  # <-- Your PDF file path\n",
    "\n",
    "    print(\"üìñ Extracting PDF text...\")\n",
    "    full_text = extract_pdf_text(pdf_path)\n",
    "    if not full_text.strip():\n",
    "        print(\"‚ùå Could not extract text from the PDF.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"üîÑ Splitting into chunks...\")\n",
    "    chunks = split_into_chunks(full_text)\n",
    "    print(f\"‚úÖ PDF split into {len(chunks)} chunks.\")\n",
    "\n",
    "    print(\"üîç Creating FAISS index...\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    index, embeddings = create_faiss_index(chunks, model)\n",
    "    print(\"‚úÖ Ready! Ask any question (type 'exit' to quit).\")\n",
    "\n",
    "    # Interactive Loop\n",
    "    while True:\n",
    "        question = input(\"\\n‚ùì Your Question: \")\n",
    "        if question.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"üëã Exiting AI Tutor. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        print(\"üîç Searching PDF for relevant content...\")\n",
    "        top_chunks = find_top_chunks(question, chunks, model, index, top_n=3)\n",
    "        combined_context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "        print(\"ü§ñ Generating answer...\\n\")\n",
    "        answer = ask_local_llm(combined_context, question)\n",
    "\n",
    "        print(f\"üí¨ AI Tutor Answer:\\n{answer}\\n\")\n",
    "\n",
    "        # Speak answer\n",
    "        print(\"üîä Speaking answer...\")\n",
    "        speak_text(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d184731d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Extracting PDF text...\n",
      "üîÑ Splitting into chunks...\n",
      "‚úÖ PDF split into 26 chunks.\n",
      "üîç Creating FAISS index...\n",
      "‚úÖ Ready! Say 'exit' to quit.\n",
      "üé§ Listening... Please speak your question.\n",
      "‚ùå Sorry, I couldn't understand. Please try again.\n",
      "üé§ Listening... Please speak your question.\n",
      "‚ùå Sorry, I couldn't understand. Please try again.\n",
      "üé§ Listening... Please speak your question.\n",
      "‚ùì You asked: what is time series analysis\n",
      "üîç Searching PDF for relevant content...\n",
      "ü§ñ Generating answer...\n",
      "\n",
      "üí¨ AI Tutor Answer:\n",
      "Time series analyzis refers to the process of examining and predicting the trends, fluctuations, and patterns in data over an extended period. It can involve various techniques such as seasonal analysis, regression, forecasting, and trend identification. The goal is to understand the underlying dynamics of the data and identify potential causes or patterns for future outcomes. Some common time series applications include weather forecasting, stock market analysis, supply chain management, and economic forecasting. To perform time series analyzis, various statistical methods such as Fourier Analysis, Trend-Forecast (TF) method, Moving Average (MA), Auto Regressive Integrated Moving Averages (ARIMA), and Seasonal Differential Autoregressive Integrated Moving Averages (SDAMA) are used. Additionally, machine learning algorithms such as Random Forest, Decision Trees, Random Projection, and Support Vector Machines (SVMs) can also be used to analyze time series data.\n",
      "\n",
      "üé§ Listening... Please speak your question.\n",
      "‚ùå Sorry, I couldn't understand. Please try again.\n",
      "üé§ Listening... Please speak your question.\n",
      "‚ùå Sorry, I couldn't understand. Please try again.\n",
      "üé§ Listening... Please speak your question.\n",
      "‚ùå Sorry, I couldn't understand. Please try again.\n",
      "üé§ Listening... Please speak your question.\n",
      "‚ùì You asked: quit\n",
      "üëã Exiting AI Tutor. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Extract text from PDF\n",
    "# ------------------------------\n",
    "def extract_pdf_text(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Split text into chunks\n",
    "# ------------------------------\n",
    "def split_into_chunks(text, chunk_size=500):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Create FAISS index\n",
    "# ------------------------------\n",
    "def create_faiss_index(chunks, model):\n",
    "    embeddings = model.encode(chunks)\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(np.array(embeddings))\n",
    "    return index, embeddings\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Find top N best chunks\n",
    "# ------------------------------\n",
    "def find_top_chunks(question, chunks, model, index, top_n=3):\n",
    "    q_embedding = model.encode([question])\n",
    "    distances, indices = index.search(np.array(q_embedding), k=top_n)\n",
    "    return [chunks[i] for i in indices[0]]\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Ask TinyLLaMA using Ollama\n",
    "# ------------------------------\n",
    "def ask_local_llm(context, question):\n",
    "    prompt = f\"\"\"You are a helpful AI tutor. Based only on the textbook content below, answer the question clearly and accurately.\n",
    "\n",
    "Text:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    response = ollama.chat(\n",
    "        model='tinyllama',\n",
    "        messages=[{'role': 'user', 'content': prompt}]\n",
    "    )\n",
    "    return response['message']['content']\n",
    "\n",
    "# ------------------------------\n",
    "# 6. Speak the answer (TTS)\n",
    "# ------------------------------\n",
    "def speak_text(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# ------------------------------\n",
    "# 7. Listen for voice question\n",
    "# ------------------------------\n",
    "def listen_question():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"üé§ Listening... Please speak your question.\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    try:\n",
    "        question = recognizer.recognize_google(audio)\n",
    "        print(f\"‚ùì You asked: {question}\")\n",
    "        return question\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"‚ùå Sorry, I couldn't understand. Please try again.\")\n",
    "        return None\n",
    "    except sr.RequestError:\n",
    "        print(\"‚ùå Voice recognition service is unavailable.\")\n",
    "        return None\n",
    "\n",
    "# ------------------------------\n",
    "# MAIN SCRIPT\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = r\"DSA Full Notes GR-20.pdf\"  # <-- Your PDF file\n",
    "\n",
    "    print(\"üìñ Extracting PDF text...\")\n",
    "    full_text = extract_pdf_text(pdf_path)\n",
    "    if not full_text.strip():\n",
    "        print(\"‚ùå Could not extract text from the PDF.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"üîÑ Splitting into chunks...\")\n",
    "    chunks = split_into_chunks(full_text)\n",
    "    print(f\"‚úÖ PDF split into {len(chunks)} chunks.\")\n",
    "\n",
    "    print(\"üîç Creating FAISS index...\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    index, embeddings = create_faiss_index(chunks, model)\n",
    "    print(\"‚úÖ Ready! Say 'exit' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        question = listen_question()\n",
    "        if not question:\n",
    "            continue\n",
    "        if question.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"üëã Exiting AI Tutor. Goodbye!\")\n",
    "            speak_text(\"Goodbye! Exiting AI Tutor.\")\n",
    "            break\n",
    "\n",
    "        print(\"üîç Searching PDF for relevant content...\")\n",
    "        top_chunks = find_top_chunks(question, chunks, model, index, top_n=3)\n",
    "        combined_context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "        print(\"ü§ñ Generating answer...\\n\")\n",
    "        answer = ask_local_llm(combined_context, question)\n",
    "\n",
    "        print(f\"üí¨ AI Tutor Answer:\\n{answer}\\n\")\n",
    "        speak_text(answer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cbb68f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Starting accuracy test...\n",
      "\n",
      "Q1: What is predictive analysis?\n",
      "AI Answer: Predictive Analytics, also known as Predictive Analytics or Predictive Analysis, involves using statistical techniques and machine learning algorithms to analyze historical data and make predictions about future outcomes. This process is typically done based on a statistical model that has been trained and tuned based on past patterns or trends. The goal of predictive analysis is to forecast, risk management, customer behavior analysis, fraud detection, etc. By providing accurate and reliable insights into data, predictive analytics can help organizations make informed decisions and improve their business operations. It uses various techniques such as linear regression, random forest, decision trees, and support vector machines (SVMs) to identify patterns and trends in the data and make predictions for future outcomes.\n",
      "Expected: Predictive analysis uses historical data and statistical models to predict future outcomes.\n",
      "Similarity Score: 0.71\n",
      "\n",
      "Q2: What is regression?\n",
      "AI Answer: Regression is a statistical technique that involves predicting a variable based on known or estimated values of other variables. It is often used in fields such as economics, finance, and healthcare to help determine whether a particular behavior or condition has an underlying relationship with another variable or set of variables. In regression analysis, the dependent variable (or variable being predicted) is usually referred to as \"y\", while the independent variables (or predictors) are denoted by the letters \"x\". The output (or outcome variable) of the analysis is commonly represented by a line or curve that connects the input values (or explanatory variables) at each data point with the output value or effect. Regression models use statistical techniques such as linear regression, multiple regression, and support vector machines to estimate a predictive relationship between dependent and independent variables using mathematical relationships. The goal of regression analysis is to identify patterns in the relationship between the dependent variable and its explanatory variables that may provide insights into the causes or effects of the dependent variable.\n",
      "Expected: Regression is a supervised learning method used to predict continuous values.\n",
      "Similarity Score: 0.71\n",
      "\n",
      "Q3: What is classification?\n",
      "AI Answer: Classification is a type of predictive modeling technique used to predict a specific category for a given input feature value. It can be used in various industries, such as healthcare, finance, and marketing. Classification models are designed to assign an output value to new data based on the relationship between the input features and the dependent variable (y). The output values can be either binary or continuous. In classification models, there are two key steps: input feature selection and feature engineering.\n",
      "\n",
      "In this step, feature selection involves identifying the important features that contribute most significantly to the dependent variable. Feature engineering is the process of transforming or manipulating the input data to match the characteristics required by a classification model. Once the feature set has been selected, the model can be trained using multiple techniques such as support vector machines (SVMs), logistic regression, and decision trees. Finally, the model can be tested on new data to predict the output value based on the chosen features and the input data.\n",
      "\n",
      "Classification models have many applications in various industries, including healthcare, finance, marketing, and customer behavior analysis. They help organizations make informed decisions by identifying patterns and trends in data, enabling them to better understand their customers and tailor their services accordingly.\n",
      "Expected: Classification is a supervised learning task that assigns data into predefined labels.\n",
      "Similarity Score: 0.51\n",
      "\n",
      "Q4: What are the steps of data preprocessing?\n",
      "AI Answer: The steps of data preprocessing can be broken down into several parts or tasks, including:\n",
      "\n",
      "1. Data cleaning: Removing any missing values, duplicates, outliers, and formatting data to match specific data formats, such as numeric, categorical or time-series.\n",
      "\n",
      "2. Data aggregation: Merging or combining related datasets into a single dataset for more accurate model predictions.\n",
      "\n",
      "3. Data transformation: Transforming data to better suit the model's needs by changing data types from numerical to categorical, numeric, or continuous variables, etc.\n",
      "\n",
      "4. Data scaling: Normalizing and scaling data for better representation in machine learning algorithms.\n",
      "\n",
      "5. Feature extraction: Identifying useful features that capture relevant information about a dataset.\n",
      "\n",
      "6. Feature engineering: Creating new features based on the extracted features or combining existing ones to create more complex features.\n",
      "\n",
      "7. Model selection: Choosing the best model based on the selected features and performance metrics, such as accuracy, precision, recall, etc.\n",
      "\n",
      "8. Data exploration: Analyzing the data to gain insights and understanding, including visualization techniques, correlation analysis, and feature importance analysis.\n",
      "\n",
      "9. Data cleaning and improvement: Continuously maintaining the dataset for better predictive performance.\n",
      "Expected: Data preprocessing involves data cleaning, normalization, transformation, feature selection, and splitting.\n",
      "Similarity Score: 0.77\n",
      "\n",
      "Q5: What is clustering?\n",
      "AI Answer: Clustering is a technique used in data analysis to group similar data points together based on certain characteristics or features. It can be done using various algorithms, and some common ones include:\n",
      "\n",
      "1. K-means clustering: This algorithm divides the dataset into k groups based on the closest observations to each other in a given feature space. K is an input parameter that determines the number of clusters.\n",
      "\n",
      "2. hierarchical clustering: This method assigns similar data points to their corresponding groups based on the distance between them in a higher-dimensional feature space. It uses hierarchical clustering, which involves grouping observations based on their similarity at multiple levels.\n",
      "\n",
      "3. DBSCAN: This algorithm clusters data points based on the minimum euclidean distance of each point to another group of points. DBSCAN is known for its ability to detect true clusters even in high-dimensional datasets.\n",
      "\n",
      "4. Agglomerative clustering: This method starts with a large number of isolated groups and merges them together until they become more similar. It is less sensitive to outliers and more robust than other clustering methods when there are many data points per group.\n",
      "\n",
      "Clustering can be used for several applications, including:\n",
      "\n",
      "1. Product segmentation: By grouping similar products based on certain characteristics or features, businesses can better target their marketing efforts and increase sales.\n",
      "\n",
      "2. Healthcare: In medical diagnosis and treatment, clustering data points based on disease severity or patient demographics can help to identify patterns and make more informed decisions.\n",
      "\n",
      "3. Social media: By grouping similar users based on their online behavior, businesses can better understand their target audience and tailor their marketing strategies accordingly.\n",
      "\n",
      "4. Finance: In stock portfolio analysis, clustering data points based on asset class or sector can help to identify patterns and make more informed investment decisions.\n",
      "Expected: Clustering is an unsupervised learning technique that groups similar data points.\n",
      "Similarity Score: 0.74\n",
      "\n",
      "‚úÖ Final Accuracy of AI Tutor: 80.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Test Questions & Expected Answers\n",
    "# ------------------------------\n",
    "qa_pairs = [\n",
    "    (\"What is predictive analysis?\", \"Predictive analysis uses historical data and statistical models to predict future outcomes.\"),\n",
    "    (\"What is regression?\", \"Regression is a supervised learning method used to predict continuous values.\"),\n",
    "    (\"What is classification?\", \"Classification is a supervised learning task that assigns data into predefined labels.\"),\n",
    "    (\"What are the steps of data preprocessing?\", \"Data preprocessing involves data cleaning, normalization, transformation, feature selection, and splitting.\"),\n",
    "    (\"What is clustering?\", \"Clustering is an unsupervised learning technique that groups similar data points.\"),\n",
    "]\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Load Similarity Model\n",
    "# ------------------------------\n",
    "similarity_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to compute semantic similarity\n",
    "def get_similarity(ans1, ans2):\n",
    "    emb1 = similarity_model.encode([ans1])\n",
    "    emb2 = similarity_model.encode([ans2])\n",
    "    return cosine_similarity(emb1, emb2)[0][0]\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Accuracy Test\n",
    "# ------------------------------\n",
    "correct = 0\n",
    "print(\"\\nüîç Starting accuracy test...\\n\")\n",
    "\n",
    "for i, (question, expected) in enumerate(qa_pairs, 1):\n",
    "    # Use your existing chunk search and LLM answering functions\n",
    "    top_chunks = find_top_chunks(question, chunks, model, index, top_n=2)\n",
    "    context = \"\\n\".join(top_chunks)\n",
    "    ai_answer = ask_local_llm(context, question)\n",
    "    \n",
    "    # Calculate similarity\n",
    "    sim = get_similarity(ai_answer, expected)\n",
    "    print(f\"Q{i}: {question}\")\n",
    "    print(f\"AI Answer: {ai_answer}\")\n",
    "    print(f\"Expected: {expected}\")\n",
    "    print(f\"Similarity Score: {sim:.2f}\\n\")\n",
    "    \n",
    "    if sim > 0.7:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = (correct / len(qa_pairs)) * 100\n",
    "print(f\"‚úÖ Final Accuracy of AI Tutor: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
